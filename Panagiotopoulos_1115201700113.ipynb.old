{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4178e5c5",
   "metadata": {},
   "source": [
    "# <div style=\"text-align:center\"> 2η Εργασία </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499e2ee1",
   "metadata": {},
   "source": [
    "#### <div style=\"text-align:center\">  Παναγιώτοπουλος Γεώργιος **1115201700113** </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106a02da",
   "metadata": {},
   "source": [
    "### <a href=\"#Ask1\"><div style=\"text-align:center\"> [Ερώτημα 1: Αναγνώριση Προσώπων (Face recognition)]</div></a>\n",
    "Σε αυτό τo ερώτημα θα εφαρμόσετε τη μέθοδο Eigenfaces (δηλαδή συνδυασμό PCA για\n",
    "εξαγωγή χαρακτηριστικών και ταξινομητή πλησιέστερου γείτονα για την αναγνώριση\n",
    "προσώπων). Θα χρησιμοποιήσετε εικόνες προσώπων από τη βάση δεδομένων προσώπων\n",
    "Yale B στην οποία υπάρχουν 10 πρόσωπα που φωτογραφήθηκαν κάτω από 64 διαφορετικές\n",
    "συνθήκες φωτισμού. Χρησιμοποιώντας την υλοποίησή σας, θα αξιολογήσετε την ικανότητα\n",
    "του αλγορίθμου Eigenfaces να χειρίζεται συνθήκες φωτισμού των εικόνων ελέγχου (test set)\n",
    "οι οποίες διαφέρουν από αυτές στις εικόνες εκπαίδευσης (training set) <br>\n",
    "Η μέθοδος Eigenfaces για την αναγνώριση προσώπων περιλαμβάνει 3 βασικά βήματα:\n",
    "1. Κάθε εικόνα διάστασης 50 x 50 pixels του συνόλου εκπαίδευσης μετατρέπεται σε\n",
    "διάνυσμα διάστασης 2500 στοιχείων και αποθηκεύεται ως στήλη στον πίνακα δεδομένων\n",
    "εκπαίδευσης Χ. Στη συνέχεια εφαρμόζουμε principal component analysis (PCA) στον πίνακα\n",
    "δεδομένων εκπαίδευσης και εξάγουμε τις d κύριες συνιστώσες (principal components). Τα d\n",
    "ιδιοδιανύσματα (eigenvectors) όταν μετατραπούν και απεικονιστούν ως εικόνες\n",
    "ονομάζονται Eigenfaces.\n",
    "2. Προβάλουμε τις εικόνες των συνόλων εκπαίδευσης και ελέγχου στο χώρο d\n",
    "διαστάσεων και με αυτόν το τρόπο εξάγουμε χαρακτηριστικά χαμηλής διάστασης (d-\n",
    "dimensional features). Ο χώρος χαμηλής διάστασης d ονομάζεται ιδιοχώρος (eigenspace).\n",
    "3. H αναγνώριση των προσώπων γίνεται στον eigenspace χρησιμοποιώντας\n",
    "ταξινομητή (ενός) πλησιέστερου γείτονα με Ευκλείδεια απόσταση ως μετρική.\n",
    "\n",
    "Από το σύνολο δεδομένων προσώπων Yale B θα χρησιμοποιήσετε τα παρακάτω υποσύνολα:\n",
    "* Set_1: person*_01.png έως person*_07.png (δηλαδή τις 7 πρώτες εικόνες κάθε προσώπου)\n",
    "* Set_2: person*_08.png έως person*_19.png\n",
    "* Set_3: person*_20.png έως person*_31.png\n",
    "* Set_4: person*_32.png εως person*_45.png\n",
    "* Set_5: person*_46.png έως person*_64.png\n",
    "Ζητούμενα:\n",
    "1. Να γράψετε μία συνάρτηση loadImages(path, set_number) η οποία παίρνει ως είσοδο το\n",
    "path στο οποίο βρίσκεται ο φάκελος των εικόνων π.χ. loadImages(“C:/images”, “Set_1”),\n",
    "διαβάζει τις εικόνες και επιστέφει έναν πίνακα δεδομένων ανάλογα με το set_number,\n",
    "όπου κάθε εικόνα αναπαρίσταται ως διάνυσμα στήλη. Η συνάρτηση επιστέφει επίσης τις\n",
    "κατηγορίες (labels) στις οποίες ανήκουν οι διαφορετικές εικόνες κωδικοποιημένες με\n",
    "ακεραίους (π.χ. 0 για φωτογραφίες που ανήκουν στο person_0, 1 για τις φωτογραφίες\n",
    "που ανήκουν στο person_1 κτλ).\n",
    "2. Να εκπαιδεύσετε την μέθοδο Eigenfaces με d = 9 και d = 30 χρησιμοποιώντας όλες τις\n",
    "εικόνες στο Set_1 (70 εικόνες) και να αναγνωρίσετε τα πρόσωπα στα Set_1 έως Set_5.\n",
    "Για κάθε Set και κάθε τιμή της διάστασης d να αναφέρετε την ακρίβεια ταξινόμησης. Για\n",
    "το Set_1 αναμένουμε 100% ακρίβεια ταξινόμησης καθώς χρησιμοποιήθηκε για την\n",
    "εκπαίδευση της μεθόδου Eigenfaces. Σχολιάστε την δυνατότητα γενίκευσης της μεθόδου\n",
    "στα διαφορετικά Sets.\n",
    "3. Να απεικονίσετε (σε μορφή εικόνας) τα 9 κύρια ιδιοδιανύσματα (9 top eigenvectors) που\n",
    "προέκυψαν αφού εκπαιδεύσατε την μέθοδο Eigenfaces στο Set_1. Τι παρατηρείτε; Τι θα\n",
    "μπορούσαμε να πούμε ότι εκφράζουν τα διαφορετικά ιδιοδιανύσματα;\n",
    "4. Να χρησιμοποιήσετε d = 9 και d = 30 Eigenfaces που βρήκατε από το Set_1, για να\n",
    "ανακατασκευάσετε μια τυχαία εικόνα από κάθε ένα από τα 5 Sets. Να απεικονίσετε τόσο\n",
    "τις αρχικές εικόνες όσο και τις ανακατασκευασμένες της για διαφορετικές τιμές του d.\n",
    "Να σχολιάσετε την ποιότητα ανακατασκευής κάθε εικόνας.\n",
    "5. Να απεικονίσετε τα 9 κύρια singular vectors που προκύπτουν αφού εφαρμόσετε SVD\n",
    "στον πίνακα δεδομένων του Set_1. Διαφέρουν τα singular vectors από τα αντίστοιχα\n",
    "ιδιοδιανύσματα; Αν ναι, γιατί;\n",
    "\n",
    "Σημείωση: Μπορείτε να χρησιμοποιήσετε είτε έτοιμες υλοποιήσεις της PCA είτε να την\n",
    "υλοποιήσετε χρησιμοποιώντας ιδοανάλυση (συναρτήσεις τύπου eig) στον πίνακα συν-\n",
    "διακύμανσης. Προτείνεται να προ-επεξεργαστείτε κάθε εικόνα αφαιρώντας τη μέση τιμή της\n",
    "και διαιρώντας με την τυπική απόκλιση των τιμών της."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2cf909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#Τα sets\n",
    "sets = {\n",
    "    1 : (1,7),\n",
    "    2 : (8,19),\n",
    "    3 : (20,31),\n",
    "    4 : (32,45),\n",
    "    5 : (46,64)\n",
    "}\n",
    "#Το \"path\"\n",
    "path = \"./faces\"\n",
    "#Προτείνεται να προ-επεξεργαστείτε κάθε εικόνα\n",
    "def normalize_image_vector(image_vector):\n",
    "    #calculate mean\n",
    "    mean_value = np.mean(image_vector)\n",
    "    #calculate the standard deviation\n",
    "    squared_diff = (image_vector - mean_value)** 2\n",
    "    variance_value = np.mean(squared_diff)\n",
    "    std_deviation = np.sqrt(variance_value)\n",
    "    #normalize the image vector\n",
    "    normalized_image_vector = (image_vector - mean_value)/std_deviation\n",
    "    return normalized_image_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1)Να γράψετε μία συνάρτηση loadImages(path, set_number)\n",
    "def loadimages(path,set_number):\n",
    "    scaler = StandardScaler()\n",
    "    start,finish = sets[set_number]\n",
    "    X = []\n",
    "    labels = []\n",
    "    for i in range(1,11): #the loop for all the people \n",
    "        result1,rest1 = divmod(i,10)\n",
    "        person = \"person\" + str(result1) + str(rest1) + \"_\" #person'idiv10''imod10'\n",
    "        for j in range(start,finish+1): # the loop for the images of them\n",
    "            result2,rest2 = divmod(j,10)\n",
    "            imagename = path + '/' + person + str(result2) + str(rest2) + \".png\" #person'idiv10''imod10'\n",
    "            image = Image.open(imagename)\n",
    "            image_vector = np.array(image).reshape(2500)\n",
    "            normalize_image_vector(image_vector)\n",
    "            X.append(image_vector)\n",
    "            labels.append(i)\n",
    "    X = np.squeeze(X)\n",
    "    X = scaler.fit_transform(X)        \n",
    "    X = np.array(X).T  # Transpose to have images as columns\n",
    "    labels = np.array(labels)\n",
    "    return X, labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef91f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2)Να εκπαιδεύσετε την μέθοδο Eigenfaces με d = 9 και d = 30\n",
    "def train_and_test(d,set_number):\n",
    "    #Train a classifier\n",
    "    X,labels = loadimages(path,set_number)\n",
    "    pca = PCA(n_components = d)\n",
    "    pca.fit(X.T)  #obligatory fit\n",
    "    eigenvectors = pca.components_\n",
    "    mean = pca.mean_\n",
    "    X_pc = pca.transform(X.T) \n",
    "    classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "    classifier.fit(X_pc,labels) #train the classifier\n",
    "    accuracies = []\n",
    "    #Make the predictions\n",
    "    for i in range(1,6):\n",
    "        images,labels = loadimages(path,i)\n",
    "        images_pc = pca.transform(images.T)\n",
    "        prediction = classifier.predict(images_pc)\n",
    "        accuracy = accuracy_score(labels,prediction)\n",
    "        accuracies.append(accuracy)\n",
    "    return accuracies,(eigenvectors,mean)\n",
    "#Print the predictions for every set\n",
    "accuracies9,(eigenfaces9,mean9) = train_and_test(9,1)\n",
    "accuracies30,(eigenfaces30,mean30) = train_and_test(30,1)\n",
    "print(accuracies9)\n",
    "print(accuracies30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd12d4cb",
   "metadata": {},
   "source": [
    "Παρατηρούμε ότι η ευστοχία του μοντέλου μας πέφτει δραστικά για τα δύο τελευταία sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41326423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#3)Να απεικονίσετε (σε μορφή εικόνας) τα 9 κύρια ιδιοδιανύσματα \n",
    "normalized_eigenfaces = []\n",
    "for i in range(9):\n",
    "    normalized_face = eigenfaces9[i]/np.linalg.norm(eigenfaces9[i])\n",
    "    normalized_eigenfaces.append(normalized_face)\n",
    "    \n",
    "reformatted = np.array(normalized_eigenfaces).reshape(9,50,50)\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(reformatted[i], cmap='bone')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761cf75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "#4)Να χρησιμοποιήσετε d = 9 και d = 30 Eigenfaces για να ανακατασκευάσετε μια τυχαία εικόνα\n",
    "#d = 9\n",
    "for i in range(1,6):\n",
    "    #Getting a random number in the range of the set\n",
    "    start, end = sets[i]\n",
    "    upto = end + 1 - start\n",
    "    rand = random.sample(range(start, end+1), 1)\n",
    "    #Readying PCA\n",
    "    X, labels = loadimages(path,1)  # Assuming loadImages returns both X and labels\n",
    "    pca = PCA(n_components=9)\n",
    "    pca.fit(X.T)\n",
    "    #Getting a random image\n",
    "    new_image = X[:, rand[0]]\n",
    "    new_image_vector = new_image.flatten()\n",
    "    #Trying to reconstruct it\n",
    "    coefficients = pca.transform([new_image_vector])\n",
    "    reconstructed_image_vector = pca.inverse_transform(coefficients)\n",
    "    reconstructed_image = reconstructed_image_vector.reshape(50, 50)\n",
    "    #Plotting Initial\n",
    "    plt.subplot(2, 5, i)\n",
    "    plt.imshow(new_image.reshape(50, 50), cmap='bone')\n",
    "    plt.axis('off')\n",
    "    #Plotting Recostruction\n",
    "    plt.subplot(2, 5, i+5)\n",
    "    plt.imshow(reconstructed_image, cmap='bone')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72619bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = 30\n",
    "for i in range(1,6):\n",
    "    #Getting a random number in the range of the set\n",
    "    start, end = sets[i]\n",
    "    upto = end + 1 - start\n",
    "    rand = random.sample(range(start, end+1), 1)\n",
    "    #Readying PCA\n",
    "    X, labels = loadimages(path,1)  # Assuming loadImages returns both X and labels\n",
    "    pca = PCA(n_components=30)\n",
    "    pca.fit(X.T)\n",
    "    #Getting a random image\n",
    "    new_image = X[:, rand[0]]\n",
    "    new_image_vector = new_image.flatten()\n",
    "    #Trying to reconstruct it\n",
    "    coefficients = pca.transform([new_image_vector])\n",
    "    reconstructed_image_vector = pca.inverse_transform(coefficients)\n",
    "    reconstructed_image = reconstructed_image_vector.reshape(50, 50)\n",
    "    #Plotting Initial\n",
    "    plt.subplot(2, 5, i)\n",
    "    plt.imshow(new_image.reshape(50, 50), cmap='bone')\n",
    "    plt.axis('off')\n",
    "    #Plotting Recostruction\n",
    "    plt.subplot(2, 5, i+5)\n",
    "    plt.imshow(reconstructed_image, cmap='bone')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75f06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5)Να απεικονίσετε τα 9 κύρια singular vectors που προκύπτουν αφού εφαρμόσετε SVD\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "# >>> import numpy as np\n",
    "# >>> np.random.seed(0)\n",
    "# >>> X_dense = np.random.rand(100, 100)\n",
    "# >>> X_dense[:, 2 * np.arange(50)] = 0\n",
    "# >>> X = csr_matrix(X_dense)\n",
    "# >>> svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
    "# >>> svd.fit(X)\n",
    "X,labels = loadimages(path,1)\n",
    "X = csr_matrix(X)\n",
    "svd = TruncatedSVD(n_components=9)\n",
    "svd.fit(X)\n",
    "vectors = svd.components_\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f62c3f8",
   "metadata": {},
   "source": [
    "### <a href=\"#Ask1\"><div style=\"text-align:center\"> [Ερώτημα 2: Ταξινόμηση εικόνων χρησιμοποιώντας SVMs]</div></a>\n",
    "\n",
    "Σε αυτό το ερώτημα, καλείστε να διερευνήσετε την επίδοση των support vector machines\n",
    "στο πρόβλημα της αναγνώρισης χειρόγραφων ψηφίων. Για το σκοπό αυτό θα\n",
    "χρησιμοποιήσετε το σύνολο δεδομένων MNIST και υλοποιήσεις αλγορίθμων της\n",
    "βιβλιοθήκης scikit-learn. Το σύνολο δεδομένων MNIST αποτελείται από 70000 εικόνες\n",
    "χειρόγραφων ψηφίων και, τυπικά, χωρίζεται σε τρία υποσύνολα: training set (50000\n",
    "εικόνες), validation set (10000 εικόνες), test set (10000 εικόνες). Κάθε εικόνα έχει διάσταση\n",
    "28 x 28 pixels και απεικονίζει ένα χειρόγραφο ψηφίο.\n",
    "\n",
    "* Ζητείται να φορτώσετε τα δεδομένα του συνόλου MNIST και να μετατρέψετε κάθε\n",
    "εικόνα σε μορφή διανύσματος διάστασης 28 x 28 = 784. Στη συνέχεια\n",
    "κανονικοποιήστε (normalize) τα δεδομένα στο διάστημα [0,1].\n",
    "* Στα SVMs υπάρχουν διάφορες επιλογές που μπορεί να επηρεάσουν την απόδοση\n",
    "τους σε προβλήματα ταξινόμησης. Παραδείγματα τέτοιων επιλογών αποτελούν ο\n",
    "τύπος του πυρήνα (kernel) και οι τιμές των διάφορων (υπερ)παραμέτρων. Ζητείται\n",
    "να εξετάσετε την επίδοση των SVMs για γραμμικό (linear SVMs) και RBF πυρήνα και\n",
    "διαφορετικές τιμές παραμέτρων ώστε να καθορίσετε το συνδυασμό\n",
    "παραμέτρων/πυρήνων που οδηγούν στη μεγαλύτερη ακρίβεια ταξινόμησης. Για\n",
    "4\n",
    "αυτό το πείραμα να χρησιμοποιήσετε 60000 εικόνες για εκπαίδευση (training) και\n",
    "10000 παραδείγματα για δοκιμές (test). Να αναφέρετε τις τιμές των παραμέτρων,\n",
    "δηλαδή τύπο πυρήνα, τιμές των C και gamma που οδηγούν στις καλύτερες επιδόσεις\n",
    "τόσο στο σύνολο εκπαίδευσης όσο και στο σύνολο δοκιμής (test set).\n",
    "* Στη συνέχεια, να εφαρμόσετε PCA στα δεδομένα επιλέγοντας 3 διαφορετικές τιμές\n",
    "για τη διατηρούμενη διακύμανση και για κάθε τιμή διακύμανσης εκτελέστε ξανά τη\n",
    "μέθοδο SVM χρησιμοποιώντας τις παραμέτρους που οδήγησαν στην καλύτερη\n",
    "επίδοση στο παραπάνω ερώτημα. Για κάθε εκτέλεση, αναφέρετε τον αριθμό των\n",
    "συνιστωσών (components) που διατηρούνται καθώς και την ακρίβειας ταξινόμησης.\n",
    "Επίσης, καταγράψτε τους χρόνους εκτέλεσης κάθε πειράματος και εξαγάγετε\n",
    "συμπεράσματα σχετικά με μια πιθανή αντιστάθμιση (trade-off) μεταξύ ακρίβειας\n",
    "ταξινόμησης, μείωσης διαστάσεων και χρόνου εκτέλεσης του αλγορίθμου"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa69d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# x_train: uint8 NumPy array of grayscale image data with shapes (60000, 28, 28), containing the training data. Pixel values range from 0 to 255.\n",
    "# y_train: uint8 NumPy array of digit labels (integers in range 0-9) with shape (60000,) for the training data.\n",
    "# x_test: uint8 NumPy array of grayscale image data with shapes (10000, 28, 28), containing the test data. Pixel values range from 0 to 255.\n",
    "# y_test: uint8 NumPy array of digit labels (integers in range 0-9) with shape (10000,) for the test data.\n",
    "(x_train, y_train), (x_test, y_test)  = tf.keras.datasets.mnist.load_data(path='mnist.npz')\n",
    "#vectorizing\n",
    "x_train = x_train.reshape(60000,784)\n",
    "x_test  = x_test.reshape(10000,784)\n",
    "#interval normalization \n",
    "x_train = x_train/np.linalg.norm(x_train) \n",
    "x_test  = x_test/np.linalg.norm(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb513727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Samples\n",
    "x_sample = x_train[:6000]\n",
    "y_sample = y_train[:6000]\n",
    "x_t_sample = x_test[:1000]\n",
    "y_t_sample = y_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b0a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#HyperParameterSearch for Linear\n",
    "model = SVC()\n",
    "space = dict()\n",
    "space['C'] = loguniform(1e-5,1000)\n",
    "space['kernel'] = ['linear']\n",
    "space['gamma'] = loguniform(1e-5,10)\n",
    "space['tol'] = loguniform(1e-5,10)\n",
    "\n",
    "#Search\n",
    "search = RandomizedSearchCV(model,space,n_iter=500,scoring='accuracy',n_jobs=-1,cv=5,random_state=1)\n",
    "result = search.fit(x_sample,y_sample)\n",
    "print(search.best_params_)\n",
    "\n",
    "#HyperParameterSearch for RBF\n",
    "model = SVC()\n",
    "space = dict()\n",
    "space['C'] = loguniform(1e-5,1000)\n",
    "space['kernel'] = ['rbf']\n",
    "space['gamma'] = loguniform(1e-5,10)\n",
    "space['tol'] = loguniform(1e-5,10)\n",
    "\n",
    "#Search\n",
    "search = RandomizedSearchCV(model,space,n_iter=500,scoring='accuracy',n_jobs=-1,cv=5,random_state=1)\n",
    "result = search.fit(x_sample,y_sample)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c8c3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear SVMs Test\n",
    "svc = SVC(C=347, kernel='linear', gamma=0.04, tol=1.7)\n",
    "svc.fit(x_sample,y_sample)\n",
    "prediction = svc.predict(x_t_sample)\n",
    "accuracy = accuracy_score(y_t_sample,prediction)\n",
    "print(\"Linear: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1db18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RBF SVMs Test\n",
    "svc = SVC(C=781, kernel='rbf', gamma=5, tol=0.08)\n",
    "svc.fit(x_sample,y_sample)\n",
    "prediction = svc.predict(x_t_sample)\n",
    "accuracy = accuracy_score(y_t_sample,prediction)\n",
    "print(\"RBF: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f13752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear SVMs\n",
    "svc = SVC(C=347, kernel='linear', gamma=0.04, tol=1.7)\n",
    "svc.fit(x_train,y_train)\n",
    "prediction = svc.predict(x_test)\n",
    "accuracy = accuracy_score(y_test,prediction)\n",
    "print(\"Linear: \", accuracy)\n",
    "\n",
    "#RBF SVMs\n",
    "svc = SVC(C=781, kernel='rbf', gamma=5, tol=0.08)\n",
    "svc.fit(x_train,y_train)\n",
    "prediction = svc.predict(x_test)\n",
    "accuracy = accuracy_score(y_test,prediction)\n",
    "print(\"RBF: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
